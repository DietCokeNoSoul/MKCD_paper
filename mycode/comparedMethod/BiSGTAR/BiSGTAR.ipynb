{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.empty_cache()\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TAR(nn.Module):\n",
    "    def __init__(self, hid_dim, out_dim, bias=False):\n",
    "        super(TAR, self).__init__()\n",
    "        # encoder-1\n",
    "        self.e1 = nn.Linear(out_dim, hid_dim, bias=bias)\n",
    "        # decoder\n",
    "        self.d1 = nn.Linear(hid_dim, out_dim, bias=bias)\n",
    "        self.Confidence = nn.Linear(hid_dim, out_dim, bias=bias)\n",
    "        self.act1 = nn.ELU()\n",
    "        self.act2 = nn.Sigmoid()\n",
    "        self.act3 = nn.Sigmoid()\n",
    "    def encoder(self, x):\n",
    "        h = self.act1(self.e1(x))\n",
    "        return h\n",
    "    def decoder(self, z):\n",
    "        h = self.act2(self.d1(z))\n",
    "        return h\n",
    "    def confidencer(self, z):\n",
    "        y = self.act3(self.Confidence(z))\n",
    "        return y\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        h = self.decoder(z)\n",
    "        y = self.confidencer(z)\n",
    "        return y, h\n",
    "class BiSGTAR(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(BiSGTAR, self).__init__()\n",
    "        dis_num = args.dis_num\n",
    "        rna_num = args.rna_num\n",
    "        self.input_drop = nn.Dropout(0.)\n",
    "        self.att_drop = nn.Dropout(0.)\n",
    "        self.FeatQC_rna = nn.Linear(dis_num, dis_num, bias=True)\n",
    "        self.FeatQC_dis = nn.Linear(rna_num, rna_num, bias=True)\n",
    "        self.AE_rna = TAR(args.hidden, dis_num)\n",
    "        self.AE_dis = TAR(args.hidden, rna_num)\n",
    "        self.act = nn.Sigmoid()\n",
    "        self.dropout = args.dropout\n",
    "    def forward(self, feat):\n",
    "        rna_quality = self.act(F.dropout(self.FeatQC_rna(feat), self.dropout))\n",
    "        dis_quality = self.act(F.dropout(self.FeatQC_dis(feat.t()), self.dropout))\n",
    "        rna_sparse_feat = torch.mul(rna_quality, feat)\n",
    "        dis_sparse_feat = torch.mul(dis_quality, feat.t())\n",
    "        yc, hc = self.AE_rna(rna_sparse_feat)\n",
    "        yd, hd = self.AE_dis(dis_sparse_feat)\n",
    "        return yc, rna_sparse_feat, rna_quality, hc, yd, dis_sparse_feat, dis_quality, hd\n",
    "# feat=torch.randn(834,138)\n",
    "# class param():\n",
    "#     def __init__(self):\n",
    "#         self.dis_num=138\n",
    "#         self.rna_num=834\n",
    "#         self.hidden=64\n",
    "#         self.dropout=0.5\n",
    "# args=param()\n",
    "# BiSGTAR(args)(feat)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\71949\\AppData\\Local\\Temp\\ipykernel_32120\\3450453342.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross:0\n",
      "cross:1\n",
      "cross:2\n",
      "cross:3\n",
      "cross:4\n"
     ]
    }
   ],
   "source": [
    "_,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n",
    "# cd = np.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\circRNA_disease.npy')\n",
    "# fea = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\cover_feature_matrix.pth')\n",
    "# tri = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\train_dataset.pth')\n",
    "# tei = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\test_data.pth')\n",
    "class param():\n",
    "    def __init__(self):\n",
    "        self.dis_num=138\n",
    "        self.rna_num=834\n",
    "        self.hidden=64\n",
    "        self.dropout=0.5\n",
    "args=param()\n",
    "res=[]\n",
    "criterion = nn.BCELoss()\n",
    "for i in range(5):\n",
    "    print('cross:%d'%i)\n",
    "    net=BiSGTAR(args).to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),8e-3,weight_decay=1e-10)\n",
    "    feat=fea[i][:834,834:834+138].float().to(device)\n",
    "    for e in range(600):\n",
    "        yl, rna_feat, rna_quality, hc, yd, dis_feat, dis_quality, hd=net(feat)\n",
    "        y = 0.5 * yl + (1 - 0.5) * yd.t()\n",
    "        rna_confidence = torch.mul(hc, feat)\n",
    "        dis_confidence = torch.mul(hd, feat.t())\n",
    "        rna_SPC = torch.mean(rna_quality)\n",
    "        rna_TAR = criterion(hc, feat) + F.mse_loss(yl, rna_confidence)\n",
    "        rna_loss = 0.8 * rna_TAR + 0.2 * rna_SPC\n",
    "        dis_SPC = torch.mean(dis_quality)\n",
    "        dis_TAR = criterion(hd, feat.t()) + F.mse_loss(yd, dis_confidence)\n",
    "        dis_loss = 0.8 * dis_TAR + 0.2 * dis_SPC\n",
    "        loss_inter = 0.8 * rna_loss + 0.2 * dis_loss\n",
    "        loss_cls = criterion(y, feat)\n",
    "        loss = 0.8* loss_cls + 0.2 * loss_inter\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    yl, rna_feat, rna_quality, hc, yd, dis_feat, dis_quality, hd=net(feat)\n",
    "    y = 0.5 * yl + (1 - 0.5) * yd.t()\n",
    "    res.append([y[tei[i][0,:],tei[i][1,:]].detach().cpu(),cd[tei[i][0,:],tei[i][1,:]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def roc_pr4_folder(test_x_ys, labels, pred_ys, ass_mat_shape):\n",
    "\tlabels_mat, pred_ys_mat, test_num= torch.zeros((ass_mat_shape)) -1, torch.zeros((ass_mat_shape)) -1, len(labels)\n",
    "\tfor i in range(test_num):\n",
    "\t\tlabels_mat[test_x_ys[i][0], test_x_ys[i][1]]= labels[i]\n",
    "\t\tpred_ys_mat[test_x_ys[i][0], test_x_ys[i][1]]= pred_ys[i]\n",
    "\tbool_mat4test= (labels_mat!= -1)\n",
    "\tfpr_ls, tpr_ls, recall_ls, prec_ls, effective_rows_len = [], [], [], [], 0\n",
    "\tfor i in range(ass_mat_shape[0]):\n",
    "\t\tif (labels_mat[i][bool_mat4test[i]]== 1).sum()> 0:\n",
    "\t\t\teffective_rows_len+= 1\n",
    "\t\t\tlabels4test1rowi= labels_mat[i][bool_mat4test[i]]\n",
    "\t\t\tpred_y4test1rowi= pred_ys_mat[i][bool_mat4test[i]]\n",
    "\t\t\tfpr4rowi, tpr4rowi, _= roc_curve(labels4test1rowi, pred_y4test1rowi)\n",
    "\t\t\tfpr_ls.append(fpr4rowi)\n",
    "\t\t\ttpr_ls.append(tpr4rowi)\n",
    "\t\t\tprecision4rowi, recall4rowi, _= precision_recall_curve(labels4test1rowi, pred_y4test1rowi)\n",
    "\t\t\tprecision4rowi[-1]= [1, 0][precision4rowi[-2]== 0]\n",
    "\t\t\tprec_ls.append(precision4rowi[::-1])\n",
    "\t\t\trecall_ls.append(recall4rowi[::-1])\n",
    "\tmean_fpr, mean_recall= np.linspace(0, 1, 100), np.linspace(0, 1, 100)\n",
    "\ttpr_ls4mean_tpr, prec_ls4mean_prec= [], []\n",
    "\tfor i in range(effective_rows_len):\n",
    "\t\ttpr_ls4mean_tpr.append(np.interp(mean_fpr, fpr_ls[i], tpr_ls[i]))\n",
    "\t\tprec_ls4mean_prec.append(np.interp(mean_fpr, recall_ls[i], prec_ls[i]))\n",
    "\tmean_tpr, mean_prec= np.mean(tpr_ls4mean_tpr, axis= 0), np.mean(prec_ls4mean_prec, axis= 0)\n",
    "\tprint(f'ROC平均值auc(mean_fpr, mean_tpr): {auc(mean_fpr, mean_tpr)}')\n",
    "\tprint(f'pr平均值auc(mean_recall, mean_prec)：{auc(mean_recall, mean_prec)}')\n",
    "\treturn mean_fpr, mean_tpr, mean_recall, mean_prec\n",
    "def roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold):\n",
    "\tmean_fpr, mean_tpr, mean_recall, mean_prec= mean_fpr_ts[0], torch.mean(mean_tpr_ts, dim= 0), mean_recall_ts[0], torch.mean(mean_prec_ts, dim= 0)\n",
    "\ttorch.save([mean_fpr, mean_tpr, mean_recall, mean_prec],'./res/data/BiSGTAR.pkl')\n",
    "\taucs4roc, aucs4pr= [], []\n",
    "\tfor i in range(k_fold):\n",
    "\t\taucs4roc.append(auc(mean_fpr_ts[i], mean_tpr_ts[i]))\n",
    "\t\tplt.plot(mean_fpr_ts[i], mean_tpr_ts[i], lw= 1, alpha= 0.3, label= 'ROC fold %d (AUC= %0.3f)' % (i+ 1, aucs4roc[i]))\n",
    "\taucs4roc_std, mean_auc4roc= np.std(aucs4roc), auc(mean_fpr, mean_tpr)\n",
    "\tplt.plot(mean_fpr, mean_tpr, color= 'b', lw= 2, alpha= 0.8, label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc4roc, aucs4roc_std))\n",
    "\tplt.title('roc curve')\n",
    "\tplt.xlabel('fpr')\n",
    "\tplt.ylabel('tpr')\n",
    "\tplt.axis([0, 1, 0, 1])\n",
    "\tplt.legend(loc= 'lower right')\n",
    "\tplt.show()\n",
    "\tfor i in range(k_fold):\n",
    "\t\taucs4pr.append(auc(mean_recall_ts[i], mean_prec_ts[i]))\n",
    "\t\tplt.plot(mean_recall_ts[i], mean_prec_ts[i], lw= 1, alpha= 0.3, label= 'PR fold %d (AUPR= %0.3f)' % (i+ 1, aucs4pr[i]))\n",
    "\taucs4pr_std, mean_auc4pr= np.std(aucs4pr), auc(mean_recall, mean_prec)\n",
    "\tplt.plot(mean_recall, mean_prec, color= 'b', lw= 2, alpha= 0.8, label= r'Mean PR (AUPR = %0.3f $\\pm$ %0.3f)' % (mean_auc4pr, aucs4pr_std))\n",
    "\tplt.title('pr curve')\n",
    "\tplt.xlabel('recall')\n",
    "\tplt.ylabel('precision')\n",
    "\tplt.axis([0, 1, 0, 1])\n",
    "\tplt.legend(loc= 'lower right')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC平均值auc(mean_fpr, mean_tpr): 0.8226320519517921\n",
      "pr平均值auc(mean_recall, mean_prec)：0.18270727400409492\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7737085869321735\n",
      "pr平均值auc(mean_recall, mean_prec)：0.18189654791194912\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.8035173443143784\n",
      "pr平均值auc(mean_recall, mean_prec)：0.17475799125956656\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7882613273150895\n",
      "pr平均值auc(mean_recall, mean_prec)：0.1993818580292777\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.8133634013450991\n",
      "pr平均值auc(mean_recall, mean_prec)：0.20511218286122695\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./res/data does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     mean_fprs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_fpr)); mean_tprs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_tpr)); mean_recalls\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_recall)); mean_precs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_prec))\n\u001b[0;32m     14\u001b[0m mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(mean_fprs), torch\u001b[38;5;241m.\u001b[39mstack(mean_tprs), torch\u001b[38;5;241m.\u001b[39mstack(mean_recalls, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mstack(mean_precs, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mroc_pr4cross_val\u001b[1;34m(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_pr4cross_val\u001b[39m(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold):\n\u001b[0;32m     36\u001b[0m \tmean_fpr, mean_tpr, mean_recall, mean_prec\u001b[38;5;241m=\u001b[39m mean_fpr_ts[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mmean(mean_tpr_ts, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m), mean_recall_ts[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mmean(mean_prec_ts, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \ttorch\u001b[38;5;241m.\u001b[39msave([mean_fpr, mean_tpr, mean_recall, mean_prec],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./res/data/BiSGTAR.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \taucs4roc, aucs4pr\u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     39\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_fold):\n",
      "File \u001b[1;32md:\\app\\anaconda3\\envs\\use-pytorch\\Lib\\site-packages\\torch\\serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 651\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32md:\\app\\anaconda3\\envs\\use-pytorch\\Lib\\site-packages\\torch\\serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32md:\\app\\anaconda3\\envs\\use-pytorch\\Lib\\site-packages\\torch\\serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ./res/data does not exist."
     ]
    }
   ],
   "source": [
    "mean_fprs, mean_tprs, mean_recalls, mean_precs= [], [], [], []\n",
    "_,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n",
    "# cd = np.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\circRNA_disease.npy')\n",
    "# fea = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\cover_feature_matrix.pth')\n",
    "# tri = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\train_dataset.pth')\n",
    "# tei = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\test_data.pth')\n",
    "for i in range(5):\n",
    "    # pred, y=torch.load('./data_circ/final_model/circ_plt_%d'%i)\n",
    "    pred, y=res[i]\n",
    "    test_idx= tei[i].T\n",
    "    test_idx= torch.stack([test_idx[:, 1], test_idx[:, 0]], dim= 1)\n",
    "    mean_fpr, mean_tpr, mean_recall, mean_prec= roc_pr4_folder(test_idx, y, pred, (138, 834))\n",
    "    mean_fprs.append(torch.tensor(mean_fpr)); mean_tprs.append(torch.tensor(mean_tpr)); mean_recalls.append(torch.tensor(mean_recall)); mean_precs.append(torch.tensor(mean_prec))\n",
    "mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts= torch.stack(mean_fprs), torch.stack(mean_tprs), torch.stack(mean_recalls, dim= 0), torch.stack(mean_precs, dim= 0)\n",
    "roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "use-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
