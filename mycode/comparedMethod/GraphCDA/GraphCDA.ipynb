{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "torch.cuda.empty_cache()\n",
    "import random\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, circRNA_number,disease_number,fcir,fdis,gcn_layers,out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.circRNA_number = circRNA_number\n",
    "        self.disease_number = disease_number\n",
    "        self.fcir= fcir\n",
    "        self.fdis= fdis\n",
    "        self.gcn_layers=gcn_layers\n",
    "        self.out_channels=out_channels\n",
    "        self.x_cir=nn.parameter.Parameter(data=torch.randn(self.circRNA_number, self.fcir), requires_grad=True)\n",
    "        self.x_dis=nn.parameter.Parameter(data=torch.randn(self.disease_number, self.fdis), requires_grad=True)\n",
    "        self.gcn_cir1_f = GCNConv(self.fcir, self.fcir)\n",
    "        self.gcn_cir2_f = GCNConv(self.fcir,self.fcir)\n",
    "        self.gcn_dis1_f = GCNConv(self.fdis, self.fdis)\n",
    "        self.gcn_dis2_f = GCNConv(self.fdis, self.fdis)\n",
    "        self.cnn_cir = nn.Conv2d(in_channels=self.gcn_layers,\n",
    "                               out_channels=self.out_channels,\n",
    "                               kernel_size=(self.fcir, 1),\n",
    "                               stride=1,\n",
    "                               bias=True)\n",
    "        self.cnn_dis = nn.Conv2d(in_channels=self.gcn_layers,\n",
    "                               out_channels=self.out_channels,\n",
    "                               kernel_size=(self.fdis, 1),\n",
    "                               stride=1,\n",
    "                               bias=True)\n",
    "        self.gat_cir1_f = GATConv(self.fcir, self.fcir,heads=4,concat=False,edge_dim=1)\n",
    "        self.gat_dis1_f = GATConv(self.fdis, self.fdis,heads=4,concat=False,edge_dim=1)\n",
    "    def forward(self, data):\n",
    "        x_cir_f1 = torch.relu(self.gcn_cir1_f(self.x_cir, data['cc']['edges'],data['cc']['edge_value']))# \n",
    "        x_cir_att= torch.relu(self.gat_cir1_f(x_cir_f1,data['cc']['edges'],data['cc']['edge_value']))#\n",
    "        x_cir_f2 = torch.relu(self.gcn_cir2_f(x_cir_att, data['cc']['edges'],data['cc']['edge_value']))#\n",
    "        x_dis_f1 = torch.relu(self.gcn_dis1_f(self.x_dis, data['dd']['edges'],data['dd']['edge_value']))#\n",
    "        x_dis_att =torch.relu(self.gat_dis1_f(x_dis_f1, data['dd']['edges'],data['dd']['edge_value']))#\n",
    "        x_dis_f2 = torch.relu(self.gcn_dis2_f(x_dis_att, data['dd']['edges'],data['dd']['edge_value']))#\n",
    "        X_cir = torch.cat((x_cir_f1, x_cir_f2), 1).t()\n",
    "        X_cir = X_cir.view(1, self.gcn_layers, self.fcir, -1)\n",
    "        X_dis = torch.cat((x_dis_f1, x_dis_f2), 1).t()\n",
    "        X_dis = X_dis.view(1, self.gcn_layers, self.fdis, -1)\n",
    "        cir_fea = self.cnn_cir(X_cir)\n",
    "        cir_fea = cir_fea.view(self.out_channels, self.circRNA_number).t()\n",
    "        dis_fea = self.cnn_dis(X_dis)\n",
    "        dis_fea = dis_fea.view(self.out_channels, self.disease_number).t()\n",
    "        return cir_fea.mm(dis_fea.t()),cir_fea,dis_fea\n",
    "# _,cd,fea,tri,tei=torch.load('./data_circ/dataset/circ_CNN.pth')\n",
    "# input={'cc':{},'dd':{}}\n",
    "# data_matrix=fea[0][:834,:834]\n",
    "# input['cc']['edges']=torch.argwhere(data_matrix>0.85).t()\n",
    "# input['cc']['edge_value']=data_matrix[input['cc']['edges'][0], input['cc']['edges'][1]].float().to(device)\n",
    "# input['cc']['edges']=input['cc']['edges'].to(device)\n",
    "# data_matrix=fea[0][834:834+138,834:834+138]\n",
    "# input['dd']['edges']=torch.argwhere(data_matrix>0).t()\n",
    "# input['dd']['edge_value']=data_matrix[input['dd']['edges'][0], input['dd']['edges'][1]].float().to(device)\n",
    "# input['dd']['edges']=input['dd']['edges'].to(device)\n",
    "# # print(input['cc']['data_matrix'].shape,input['dd']['data_matrix'].shape)\n",
    "# net=GCN(circRNA_number=834,\n",
    "#         disease_number=138,\n",
    "#         fcir=64,\n",
    "#         fdis=64,\n",
    "#         gcn_layers=2,\n",
    "#         out_channels=2).to(device)\n",
    "# net(input)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\71949\\AppData\\Local\\Temp\\ipykernel_14704\\1201822944.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross:0\n",
      "tensor(0.7397, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1343, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0995, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1448, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1160, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0683, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1100, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0674, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0907, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1022, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0971, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0889, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0795, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0702, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0623, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0568, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0542, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0537, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0540, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0534, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0513, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0480, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0448, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0425, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0415, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0414, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0415, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0412, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0404, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0394, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0383, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0376, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0373, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0372, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0370, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0365, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0358, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0353, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0351, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0351, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0350, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0350, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0348, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0346, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0344, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0342, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0342, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0341, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0340, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0338, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0337, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0335, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0335, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0334, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0333, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0332, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0331, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0330, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0329, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0328, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0328, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0327, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0326, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0325, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0324, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0323, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0322, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0320, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0319, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0318, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0317, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0316, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0314, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0313, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0311, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0310, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0308, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0307, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0305, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0304, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0302, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0300, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0299, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0297, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0295, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0293, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0291, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0289, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0287, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0285, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0283, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0281, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0279, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0276, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0274, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0272, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0269, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0267, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0264, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "train time: 1.8125545978546143\n",
      "test time: 0.7568063735961914\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "_,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n",
    "# # 设置随机种子\n",
    "# def set_seed(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed(seed)\n",
    "#         torch.cuda.manual_seed_all(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "# cd = np.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\circRNA_disease.npy')\n",
    "# fea = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\cover_feature_matrix.pth')\n",
    "# tri = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\train_dataset.pth')\n",
    "# tei = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\test_data.pth')\n",
    "seedIndex = [2048, 2048, 2048, 2048, 2048] \n",
    "res=[]\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "for i in range(1):    \n",
    "    # set_seed(seedIndex[i])\n",
    "    print('cross:%d'%i)\n",
    "    net=GCN(circRNA_number=834,\n",
    "        disease_number=138,\n",
    "        fcir=128,\n",
    "        fdis=128,\n",
    "        gcn_layers=2,\n",
    "        out_channels=128).to(device)\n",
    "    optimizer=torch.optim.Adam(net.parameters(),lr=0.005)#weight_decay=5e-5\n",
    "    feat=fea[i][:834,834:834+138].float()\n",
    "    data_matrix=fea[i][:834,:834]\n",
    "    input={'cc':{},'dd':{}}\n",
    "    input['cc']['edges']=torch.argwhere(data_matrix>0.85).t()\n",
    "    input['cc']['edge_value']=data_matrix[input['cc']['edges'][0], input['cc']['edges'][1]].float().to(device)\n",
    "    input['cc']['edges']=input['cc']['edges'].to(device)\n",
    "    data_matrix=fea[i][834:834+138,834:834+138]\n",
    "    input['dd']['edges']=torch.argwhere(data_matrix>0).t()\n",
    "    input['dd']['edge_value']=data_matrix[input['dd']['edges'][0], input['dd']['edges'][1]].float().to(device)\n",
    "    input['dd']['edges']=input['dd']['edges'].to(device)\n",
    "    train_start_time = time.time()\n",
    "    for e in range(100):\n",
    "        score,x,y=net(input)\n",
    "        loss = criterion(score, feat.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(loss.item())\n",
    "    train_end_time = time.time()\n",
    "    print('train time:', train_end_time - train_start_time)\n",
    "    test_start_time = time.time()\n",
    "    score,x,y=net(input)\n",
    "    x,y=x.detach().cpu(),y.detach().cpu()\n",
    "    clf = RandomForestClassifier(n_estimators=200,n_jobs=11,max_depth=20)\n",
    "    clf.fit(torch.cat([x[tri[i][0,:]],y[tri[i][1,:]]],dim=1), cd[tri[i][0,:],tri[i][1,:]])\n",
    "    y_prob = clf.predict_proba(torch.cat([x[tei[i][0,:]],y[tei[i][1,:]]],dim=1))\n",
    "    res.append([y_prob[:,0],cd[tei[i][0,:],tei[i][1,:]]])\n",
    "    test_end_time = time.time()\n",
    "    print('test time:', test_end_time - test_start_time)\n",
    "    torch.save([y_prob[:,0],cd[tei[i][0,:],tei[i][1,:]]],f'GraphCDA_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def roc_pr4_folder(test_x_ys, labels, pred_ys, ass_mat_shape):\n",
    "\tlabels_mat, pred_ys_mat, test_num= torch.zeros((ass_mat_shape)) -1, torch.zeros((ass_mat_shape)) -1, len(labels)\n",
    "\tfor i in range(test_num):\n",
    "\t\tlabels_mat[test_x_ys[i][0], test_x_ys[i][1]]= labels[i]\n",
    "\t\tpred_ys_mat[test_x_ys[i][0], test_x_ys[i][1]]= pred_ys[i]\n",
    "\tbool_mat4test= (labels_mat!= -1)\n",
    "\tfpr_ls, tpr_ls, recall_ls, prec_ls, effective_rows_len = [], [], [], [], 0\n",
    "\tfor i in range(ass_mat_shape[0]):\n",
    "\t\tif (labels_mat[i][bool_mat4test[i]]== 1).sum()> 0:\n",
    "\t\t\teffective_rows_len+= 1\n",
    "\t\t\tlabels4test1rowi= labels_mat[i][bool_mat4test[i]]\n",
    "\t\t\tpred_y4test1rowi= pred_ys_mat[i][bool_mat4test[i]]\n",
    "\t\t\tfpr4rowi, tpr4rowi, _= roc_curve(labels4test1rowi, pred_y4test1rowi)\n",
    "\t\t\tfpr_ls.append(fpr4rowi)\n",
    "\t\t\ttpr_ls.append(tpr4rowi)\n",
    "\t\t\tprecision4rowi, recall4rowi, _= precision_recall_curve(labels4test1rowi, pred_y4test1rowi)\n",
    "\t\t\tprecision4rowi[-1]= [1, 0][precision4rowi[-2]== 0]\n",
    "\t\t\tprec_ls.append(precision4rowi[::-1])\n",
    "\t\t\trecall_ls.append(recall4rowi[::-1])\n",
    "\tmean_fpr, mean_recall= np.linspace(0, 1, 100), np.linspace(0, 1, 100)\n",
    "\ttpr_ls4mean_tpr, prec_ls4mean_prec= [], []\n",
    "\tfor i in range(effective_rows_len):\n",
    "\t\ttpr_ls4mean_tpr.append(np.interp(mean_fpr, fpr_ls[i], tpr_ls[i]))\n",
    "\t\tprec_ls4mean_prec.append(np.interp(mean_fpr, recall_ls[i], prec_ls[i]))\n",
    "\tmean_tpr, mean_prec= np.mean(tpr_ls4mean_tpr, axis= 0), np.mean(prec_ls4mean_prec, axis= 0)\n",
    "\tprint(f'ROC平均值auc(mean_fpr, mean_tpr): {auc(mean_fpr, mean_tpr)}')\n",
    "\tprint(f'pr平均值auc(mean_recall, mean_prec)：{auc(mean_recall, mean_prec)}')\n",
    "\treturn mean_fpr, mean_tpr, mean_recall, mean_prec\n",
    "def roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold):\n",
    "\tmean_fpr, mean_tpr, mean_recall, mean_prec= mean_fpr_ts[0], torch.mean(mean_tpr_ts, dim= 0), mean_recall_ts[0], torch.mean(mean_prec_ts, dim= 0)\n",
    "\ttorch.save([mean_fpr, mean_tpr, mean_recall, mean_prec],'GraphCDA.pkl')\n",
    "\taucs4roc, aucs4pr= [], []\n",
    "\tfor i in range(k_fold):\n",
    "\t\taucs4roc.append(auc(mean_fpr_ts[i], mean_tpr_ts[i]))\n",
    "\t\tplt.plot(mean_fpr_ts[i], mean_tpr_ts[i], lw= 1, alpha= 0.3, label= 'ROC fold %d (AUC= %0.3f)' % (i+ 1, aucs4roc[i]))\n",
    "\taucs4roc_std, mean_auc4roc= np.std(aucs4roc), auc(mean_fpr, mean_tpr)\n",
    "\tplt.plot(mean_fpr, mean_tpr, color= 'b', lw= 2, alpha= 0.8, label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc4roc, aucs4roc_std))\n",
    "\tplt.title('roc curve')\n",
    "\tplt.xlabel('fpr')\n",
    "\tplt.ylabel('tpr')\n",
    "\tplt.axis([0, 1, 0, 1])\n",
    "\tplt.legend(loc= 'lower right')\n",
    "\tplt.show()\n",
    "\tfor i in range(k_fold):\n",
    "\t\taucs4pr.append(auc(mean_recall_ts[i], mean_prec_ts[i]))\n",
    "\t\tplt.plot(mean_recall_ts[i], mean_prec_ts[i], lw= 1, alpha= 0.3, label= 'PR fold %d (AUPR= %0.3f)' % (i+ 1, aucs4pr[i]))\n",
    "\taucs4pr_std, mean_auc4pr= np.std(aucs4pr), auc(mean_recall, mean_prec)\n",
    "\tplt.plot(mean_recall, mean_prec, color= 'b', lw= 2, alpha= 0.8, label= r'Mean PR (AUPR = %0.3f $\\pm$ %0.3f)' % (mean_auc4pr, aucs4pr_std))\n",
    "\tplt.title('pr curve')\n",
    "\tplt.xlabel('recall')\n",
    "\tplt.ylabel('precision')\n",
    "\tplt.axis([0, 1, 0, 1])\n",
    "\tplt.legend(loc= 'lower right')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7107374459824202\n",
      "pr平均值auc(mean_recall, mean_prec)：0.1511844474249854\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7244262632296489\n",
      "pr平均值auc(mean_recall, mean_prec)：0.1380788996662683\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7770683717172567\n",
      "pr平均值auc(mean_recall, mean_prec)：0.21064190403449687\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7131902028154088\n",
      "pr平均值auc(mean_recall, mean_prec)：0.17459663960364835\n",
      "ROC平均值auc(mean_fpr, mean_tpr): 0.7191574755230659\n",
      "pr平均值auc(mean_recall, mean_prec)：0.200606959125948\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'mean_fpr' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     mean_fprs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_fpr)); mean_tprs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_tpr)); mean_recalls\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_recall)); mean_precs\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(mean_prec))\n\u001b[0;32m     14\u001b[0m mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(mean_fprs), torch\u001b[38;5;241m.\u001b[39mstack(mean_tprs), torch\u001b[38;5;241m.\u001b[39mstack(mean_recalls, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mstack(mean_precs, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, \u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36mroc_pr4cross_val\u001b[1;34m(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_pr4cross_val\u001b[39m(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, k_fold):\n\u001b[1;32m---> 36\u001b[0m \ttorch\u001b[38;5;241m.\u001b[39msave([mean_fpr, mean_tpr, mean_recall, mean_prec],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphCDA.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \tmean_fpr, mean_tpr, mean_recall, mean_prec \u001b[38;5;241m=\u001b[39m mean_fpr_ts[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mmean(mean_tpr_ts, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), mean_recall_ts[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mmean(mean_prec_ts, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     39\u001b[0m \tmean_auc4roc \u001b[38;5;241m=\u001b[39m auc(mean_fpr, mean_tpr)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'mean_fpr' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "mean_fprs, mean_tprs, mean_recalls, mean_precs= [], [], [], []\n",
    "_,cd,fea,tri,tei=torch.load('circ_CNN.pth')\n",
    "# cd = np.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\circRNA_disease.npy')\n",
    "# fea = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\cover_feature_matrix.pth')\n",
    "# tri = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\train_dataset.pth')\n",
    "# tei = torch.load(rf'E:\\CompeletedMethodsCodeAndPaper\\data_circ\\dataset\\test_data.pth')\n",
    "for i in range(5):\n",
    "    pred, y=torch.load('GraphCDA_%d.pth'%i)\n",
    "    # pred, y=res[i]\n",
    "    test_idx= tei[i].T\n",
    "    test_idx= torch.stack([test_idx[:, 1], test_idx[:, 0]], dim= 1)\n",
    "    mean_fpr, mean_tpr, mean_recall, mean_prec= roc_pr4_folder(test_idx, y, pred, (138, 834))\n",
    "    mean_fprs.append(torch.tensor(mean_fpr)); mean_tprs.append(torch.tensor(mean_tpr)); mean_recalls.append(torch.tensor(mean_recall)); mean_precs.append(torch.tensor(mean_prec))\n",
    "mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts= torch.stack(mean_fprs), torch.stack(mean_tprs), torch.stack(mean_recalls, dim= 0), torch.stack(mean_precs, dim= 0)\n",
    "roc_pr4cross_val(mean_fpr_ts, mean_tpr_ts, mean_recall_ts, mean_prec_ts, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "use-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
